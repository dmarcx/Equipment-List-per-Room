
import streamlit as st
from streamlit_webrtc import webrtc_streamer, AudioProcessorBase, ClientSettings
import whisper
import openai
import numpy as np
import av
import os
import tempfile

st.set_page_config(page_title="ğŸ™ï¸ ×©×™×—×” ×§×•×œ×™×ª ×¢× GPT", layout="centered")

# ××¤×ª×— ×”-API ×©×œ OpenAI
openai.api_key = os.environ.get("OPENAI_API_KEY")

# ×˜×¢×™× ×ª ××•×“×œ Whisper
@st.cache_resource
def load_whisper_model():
    return whisper.load_model("base")

model = load_whisper_model()

# ×”×¦×’×ª ×›×•×ª×¨×ª
st.title("ğŸ¤ ×©×™×—×” ×§×•×œ×™×ª ×¢× GPT")
st.info("×“×‘×¨ ××œ ×”××™×§×¨×•×¤×•×Ÿ â€“ ×”×§×œ×˜×” ×ª× ×•×ª×— ×•×ª×™×©×œ×— ×œÖ¾GPT.")

# ×©××™×¨×ª ×”×™×¡×˜×•×¨×™×™×ª ×©×™×—×”
if "chat_history" not in st.session_state:
    st.session_state.chat_history = []

# ×¢×™×‘×•×“ ×§×•×œ
class AudioProcessor(AudioProcessorBase):
    def __init__(self) -> None:
        self.recorded_data = []

    def recv(self, frame: av.AudioFrame) -> av.AudioFrame:
        audio = frame.to_ndarray()
        self.recorded_data.append(audio)
        return frame

# ×××©×§ ×”×§×œ×˜×”
ctx = webrtc_streamer(
    key="speech-to-text",
    mode="SENDRECV",
    client_settings=ClientSettings(media_stream_constraints={"audio": True, "video": False}),
    audio_processor_factory=AudioProcessor,
    async_processing=True,
)

# ×›×¤×ª×•×¨ ×œ×”×¤×¢×œ×ª ×”× ×™×ª×•×— ×”×§×•×œ×™
if ctx.audio_processor and st.button("ğŸ” ×©×œ×— ×œ-GPT"):
    with st.spinner("â³ ×××™×¨ ×§×•×œ ×œ×˜×§×¡×˜..."):
        audio_data = np.concatenate(ctx.audio_processor.recorded_data, axis=0).flatten()
        temp_audio_path = tempfile.mktemp(suffix=".wav")
        import soundfile as sf
        sf.write(temp_audio_path, audio_data, 16000)

        transcription = model.transcribe(temp_audio_path)["text"]
        st.success(f"ğŸ—£ï¸ ××ª×” ×××¨×ª: {transcription}")

        # ×©××™×¨×” ×‘×”×™×¡×˜×•×¨×™×”
        st.session_state.chat_history.append(("ğŸ‘¤", transcription))

    with st.spinner("ğŸ¤– GPT ×—×•×©×‘..."):
        response = openai.ChatCompletion.create(
            model="gpt-4",
            messages=[
                {"role": "system", "content": "××ª×” ×¢×•×–×¨ ×—×›× ×œ×‘×“×™×§×ª ×¦×™×•×“."},
                *[
                    {"role": "user" if role == "ğŸ‘¤" else "assistant", "content": msg}
                    for role, msg in st.session_state.chat_history
                ],
            ]
        )
        gpt_reply = response.choices[0].message.content.strip()
        st.session_state.chat_history.append(("ğŸ¤–", gpt_reply))
        st.markdown(f"**GPT:** {gpt_reply}")

# ×”×¦×’×ª ×”×™×¡×˜×•×¨×™×”
st.divider()
st.markdown("## ğŸ§¾ ×©×™×—×” ×¢×“ ×›×”:")
for role, msg in reversed(st.session_state.chat_history):
    st.markdown(f"**{role}**: {msg}")
